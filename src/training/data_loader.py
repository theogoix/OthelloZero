import numpy as np
import struct
from pathlib import Path
from typing import List, Tuple, Optional, Union
import torch
from torch.utils.data import Dataset


class TrainingExample:
    """Single training example from self-play"""
    def __init__(self, state: np.ndarray, visit_counts: np.ndarray, outcome: float):
        self.state = state  # [3, 8, 8] float32
        self.visit_counts = visit_counts  # [64] int32
        self.outcome = outcome  # -1, 0, or 1
    
    def __repr__(self):
        return f"TrainingExample(outcome={self.outcome}, visits_sum={self.visit_counts.sum()})"


class OthelloDataLoader:
    """Load binary training data generated by C++ self-play"""
    
    # File format constants
    MAGIC = 0x4F544844  # "OTHD"
    VERSION = 1
    
    # Size of each example in bytes
    EXAMPLE_SIZE = (
        8 + 8 + 8 + 1 +  # State: currentDiscs, opponentDiscs, legalMoves, lastMoveWasPass
        64 * 4 +          # Visit counts: 64 × int32
        1                 # Outcome: int8
    )  # Total: 282 bytes
    
    def __init__(self, data_path: str):
        self.data_path = Path(data_path)
        if not self.data_path.exists():
            raise FileNotFoundError(f"Data file not found: {data_path}")
    
    def load_all(self, verbose: bool = True) -> List[TrainingExample]:
        """Load all examples from file"""
        examples = []
        
        with open(self.data_path, 'rb') as f:
            # Read header
            magic = struct.unpack('I', f.read(4))[0]
            if magic != self.MAGIC:
                raise ValueError(f"Invalid file format. Expected magic {self.MAGIC:08x}, got {magic:08x}")
            
            version = struct.unpack('I', f.read(4))[0]
            if version != self.VERSION:
                raise ValueError(f"Unsupported version {version}")
            
            num_examples = struct.unpack('Q', f.read(8))[0]
            
            if verbose:
                print(f"Loading {num_examples:,} examples from {self.data_path.name}")
            
            # Read examples
            for i in range(num_examples):
                example = self._read_example(f)
                examples.append(example)
                
                if verbose and (i + 1) % 10000 == 0:
                    print(f"  Progress: {i + 1:,}/{num_examples:,} examples")
            
            if verbose:
                print(f"  ✓ Loaded {len(examples):,} examples")
        
        return examples
    
    def _read_example(self, f) -> TrainingExample:
        """Read single example from binary file"""
        # Read state (25 bytes)
        current_discs = struct.unpack('Q', f.read(8))[0]
        opponent_discs = struct.unpack('Q', f.read(8))[0]
        legal_moves = struct.unpack('Q', f.read(8))[0]
        last_move_was_pass = struct.unpack('?', f.read(1))[0]
        
        # Read visit counts (256 bytes)
        visit_counts = np.frombuffer(f.read(64 * 4), dtype=np.int32)
        
        # Read outcome (1 byte)
        outcome = struct.unpack('b', f.read(1))[0]
        
        # Convert bitboards to tensor
        state = self._bitboards_to_tensor(current_discs, opponent_discs, legal_moves)
        
        return TrainingExample(state, visit_counts, float(outcome))
    
    def _bitboards_to_tensor(
        self,
        current_discs: int,
        opponent_discs: int,
        legal_moves: int
    ) -> np.ndarray:
        """Convert bitboards to [3, 8, 8] numpy array"""
        tensor = np.zeros((3, 8, 8), dtype=np.float32)
        
        for pos in range(64):
            row = pos // 8
            col = pos % 8
            mask = 1 << pos
            
            # Channel 0: Current player's discs
            if current_discs & mask:
                tensor[0, row, col] = 1.0
            
            # Channel 1: Opponent's discs
            if opponent_discs & mask:
                tensor[1, row, col] = 1.0
            
            # Channel 2: Legal moves
            if legal_moves & mask:
                tensor[2, row, col] = 1.0
        
        return tensor
    
    def get_statistics(self, examples: List[TrainingExample]) -> dict:
        """Compute statistics about the dataset"""
        outcomes = [ex.outcome for ex in examples]
        
        wins = sum(1 for o in outcomes if o > 0.5)
        losses = sum(1 for o in outcomes if o < -0.5)
        draws = sum(1 for o in outcomes if -0.5 <= o <= 0.5)
        
        return {
            'total_examples': len(examples),
            'wins': wins,
            'losses': losses,
            'draws': draws,
            'win_rate': wins / len(examples) if examples else 0,
            'draw_rate': draws / len(examples) if examples else 0,
        }


class OthelloDataset(Dataset):
    """PyTorch Dataset for Othello training data with augmentation"""
    
    def __init__(
        self,
        examples: List[TrainingExample],
        temperature: float = 1.0,
        augment: bool = True
    ):
        self.examples = examples
        self.temperature = temperature
        self.augment = augment
    
    def __len__(self) -> int:
        return len(self.examples)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        example = self.examples[idx]
        
        # Apply data augmentation (8x via rotation and flip)
        if self.augment:
            state, visit_counts = self._augment(example.state, example.visit_counts)
        else:
            state = example.state
            visit_counts = example.visit_counts
        
        # Convert visit counts to policy target with temperature
        policy_target = self._apply_temperature(visit_counts, self.temperature)
        
        # Convert to tensors
        state_tensor = torch.from_numpy(state)
        policy_tensor = torch.from_numpy(policy_target)
        value_tensor = torch.tensor([example.outcome], dtype=torch.float32)
        
        return state_tensor, policy_tensor, value_tensor
    
    def _apply_temperature(self, visit_counts: np.ndarray, temperature: float) -> np.ndarray:
        """Convert visit counts to policy distribution with temperature"""
        visit_counts = visit_counts.astype(np.float32)
        
        if temperature < 0.01:
            # One-hot: all mass on most visited move
            policy = np.zeros(64, dtype=np.float32)
            best_move = np.argmax(visit_counts)
            policy[best_move] = 1.0
            return policy
        
        # Apply temperature: visits^(1/T)
        with np.errstate(divide='ignore', invalid='ignore'):
            policy = np.power(visit_counts, 1.0 / temperature)
            policy = np.nan_to_num(policy, 0.0)
        
        # Normalize
        total = np.sum(policy)
        if total > 0:
            policy = policy / total
        else:
            # Uniform if all zeros (shouldn't happen)
            policy = np.ones(64, dtype=np.float32) / 64.0
        
        return policy
    
    def _augment(
        self,
        state: np.ndarray,
        visit_counts: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """Apply random rotation/flip for data augmentation (8 symmetries)"""
        # Random rotation (0, 90, 180, 270 degrees)
        k = np.random.randint(0, 4)
        
        # Random flip (horizontal)
        flip = np.random.random() < 0.5
        
        # Apply to state [3, 8, 8]
        state_aug = np.rot90(state, k, axes=(1, 2)).copy()
        if flip:
            state_aug = np.flip(state_aug, axis=2).copy()
        
        # Apply to visit counts (reshape to 8x8, transform, flatten)
        visit_counts_2d = visit_counts.reshape(8, 8)
        visit_counts_2d = np.rot90(visit_counts_2d, k)
        if flip:
            visit_counts_2d = np.flip(visit_counts_2d, axis=1)
        visit_counts_aug = visit_counts_2d.flatten().copy()
        
        return state_aug, visit_counts_aug


# Utility functions
def load_multiple_files(
    file_paths: Union[List[str], str],
    verbose: bool = True
) -> List[TrainingExample]:
    """Load examples from one or more data files"""
    if isinstance(file_paths, str):
        file_paths = [file_paths]
    
    all_examples = []
    
    for path in file_paths:
        if verbose:
            print(f"\nLoading: {path}")
        loader = OthelloDataLoader(path)
        examples = loader.load_all(verbose=verbose)
        all_examples.extend(examples)
    
    if verbose and len(file_paths) > 1:
        print(f"\n{'='*70}")
        print(f"Total examples from {len(file_paths)} files: {len(all_examples):,}")
        print(f"{'='*70}")
    
    return all_examples


def print_dataset_statistics(examples: List[TrainingExample]):
    """Print detailed statistics about the dataset"""
    if not examples:
        print("No examples to analyze")
        return
    
    # Use loader to compute stats
    loader = OthelloDataLoader("dummy")  # Path doesn't matter for stats
    stats = loader.get_statistics(examples)
    
    print("\nDataset Statistics:")
    print("-" * 70)
    print(f"  Total examples: {stats['total_examples']:,}")
    print(f"  Wins:           {stats['wins']:,} ({stats['win_rate']:.1%})")
    print(f"  Losses:         {stats['losses']:,} ({1 - stats['win_rate'] - stats['draw_rate']:.1%})")
    print(f"  Draws:          {stats['draws']:,} ({stats['draw_rate']:.1%})")
    print("-" * 70)